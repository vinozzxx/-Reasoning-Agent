#  Multi-Step Reasoning Agent with Selfâ€‘Checking

This project implements a **multiâ€‘step reasoning agent** that solves structured word problems using a **Planner â†’ Executor â†’ Verifier** architecture. The agent produces accurate answers while **hiding raw chainâ€‘ofâ€‘thought**, exposing only short, userâ€‘friendly reasoning and metadata for debugging.

This repository was built as part of a **Junior AI/ML / GenAI Engineer assignment**.

---

##  Key Features

*  Plannerâ€“Executorâ€“Verifier agent loop
*  Dynamic retries when verification fails
*  Chainâ€‘ofâ€‘thought hidden from end users
*  Modular prompt design (no hardâ€‘coded prompts)
*  CLI / APIâ€‘ready architecture
*  Easy to swap LLM providers (Groq / OpenAI / etc.)

---

##  Problem Types Supported

* Time difference calculations
* Arithmetic & logical reasoning
* Constraint satisfaction problems
* Multiâ€‘step word problems

**Example:**

> *â€œA meeting needs 60 minutes. Free slots are 09:00â€“09:30, 09:45â€“10:30, 11:00â€“12:00. Which slots fit?â€*

---

##  Architecture Overview

The agent runs in **three internal phases**:

### 1ï¸ Planner

* Reads the user question
* Breaks it into a concise stepâ€‘byâ€‘step plan
* Example steps: parse â†’ extract data â†’ compute â†’ validate â†’ format

### 2ï¸ Executor

* Executes the plan step by step
* Produces intermediate calculations
* Uses Python or LLM calls as needed

### 3ï¸ Verifier

* Independently checks the solution
* Validates constraints and consistency
* Triggers retries if errors are detected

Only the **final answer + short explanation** are shown to the user.

---

##  Project Structure

```
.
â”œâ”€â”€ .venv/                     # Virtual environment
â”œâ”€â”€ prompts/                   # Prompt templates
â”‚   â”œâ”€â”€ planner_prompt.txt     # Planner instructions
â”‚   â”œâ”€â”€ executor_prompt.txt    # Executor instructions
â”‚   â””â”€â”€ verifier_prompt.txt    # Verifier instructions
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/                 # Core agent logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ api.py             # API / interface layer
â”‚   â”‚   â”œâ”€â”€ planner.py         # Planner module
â”‚   â”‚   â”œâ”€â”€ executor.py        # Executor module
â”‚   â”‚   â”œâ”€â”€ verifier.py        # Verifier module
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts.py             # Prompt loader & manager
â”‚   â”œâ”€â”€ tests.py               # Test cases & evaluation
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ .env                       # Environment variables (API keys)
â”œâ”€â”€ app.py                     # Entry point (CLI / API runner)
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

##  Where Prompts Live

All prompts are **separated from code** and stored under:

```
prompts/
â”œâ”€â”€ planner_prompt.txt
â”œâ”€â”€ executor_prompt.txt
â””â”€â”€ verifier_prompt.txt
```

This makes the system:

* Easy to debug
* Easy to tune
* Easy to swap LLMs

---

##  How to Run

### 1ï¸ Create virtual environment

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

### 2ï¸ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸ Add environment variables

Create a `.env` file:

```
LLM_API_KEY=your_api_key_here
```

### 4ï¸ Run the agent

```bash
python app.py
```

---

##  Output Format (JSON)

```json
{
  "answer": "<final short answer>",
  "status": "success",
  "reasoning_visible_to_user": "<short explanation>",
  "metadata": {
    "plan": "<abbreviated internal plan>",
    "checks": [
      {
        "check_name": "Time consistency",
        "passed": true,
        "details": "Verified independently"
      }
    ],
    "retries": 0
  }
}
```

---

##  Testing & Evaluation

* Includes **easy + tricky test cases**
* Logs:

  * Question
  * Final output
  * Verification result
  * Retry count

Test file:

```
src/tests.py
```

---

##  Screenshots

> ğŸ“Œ **Add screenshots here before submission**

Suggested screenshots:

* Project folder structure (VS Code)
* Sample input question
* JSON output result
* Verification pass/fail example

Example:

```md
![Project Structure](screenshots/project_structure.png)
```

---

##  Prompt Design Rationale

* Planner prompt focuses on **explicit step enumeration**
* Executor prompt enforces **stepâ€‘byâ€‘step execution**
* Verifier prompt ensures **independent validation**

### What didnâ€™t work well

* Singleâ€‘pass reasoning without verification
* Mixing planning + execution in one prompt

### Future Improvements

* Add confidence scoring
* Parallel verification strategies
* RAG for domainâ€‘specific knowledge

---

##  Author

**Vinod Kumar**
Junior AI/ML Engineer Candidate

---

â­ *If you find this project useful, feel free to star the repository.*
